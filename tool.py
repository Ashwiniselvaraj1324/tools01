"""
streamlit_app.py
A tiny Streamlit chatâ€‘style app to answer *rightâ€‘now* questions with Googleâ€¯Geminiâ€¯1.5â€¯Flash
and live web search (DuckDuckGo).  Uses LangChainâ€™s ZERO_SHOT_REACT_DESCRIPTION agent.

ğŸ”‘  IMPORTANT â€“ replace the hardâ€‘coded GEMINI_API_KEY below with **your** real key.
"""

import logging
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools import DuckDuckGoSearchRun
from langchain.agents import initialize_agent, AgentType

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Minimal logging (silence the LangChain chatty bits)
logging.getLogger("langchain").setLevel(logging.ERROR)

# 2. Put your Gemini key HERE (hardâ€‘coded as requested) ğŸ”‘
GEMINI_API_KEY = "AIzaSyCf7rxCiOtbLI5SnmjDRV9PS9WxWWk8uTI"

# 3. Build the LLM & search tool just once (cached)
@st.cache_resource(show_spinner=False)
def build_agent():
    llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",     # fast, upâ€‘toâ€‘date reasoning
        google_api_key=GEMINI_API_KEY,
        temperature=0.4,
    )
    search_tool = DuckDuckGoSearchRun()
    return initialize_agent(
        tools=[search_tool],
        llm=llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=False,
    )

agent = build_agent()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Streamlit UI
st.set_page_config(page_title="Live Q&A ğŸ¤–ğŸŒ", page_icon="ğŸŒ")
st.title("ğŸŒâ€¯Realâ€‘Time Q&A with GeminiÂ +Â DuckDuckGo ğŸ”")

# Helpful subtitle & hint
st.markdown(
    "Ask about **anything happening right now** â€“ news events, fresh facts, "
    "or recent releases. Iâ€™ll combine Googleâ€¯Geminiâ€™s reasoning with live "
    "DuckDuckGo results.  \n\n"
    "Examples:  \nâ€¢ *â€œWho won yesterdayâ€™s IPL match?â€*  \n"
    "â€¢ *â€œLatest iPhone 16 specs leak?â€*"
)

user_query = st.text_input("ğŸ’¬Â Your question", "")
ask_btn = st.button("AskÂ ğŸ¤”")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. Run the agent & display the answer
if ask_btn or (user_query and not st.session_state.get("ran_once")):
    st.session_state["ran_once"] = True  # avoid autoâ€‘rerun loops
    if not user_query.strip():
        st.warning("Please type a question first. âœï¸")
    else:
        with st.spinner("Thinkingâ€¦"):
            try:
                response = agent.run(user_query)
                st.success("Hereâ€™s what I found:")
                st.write(response)
            except Exception as err:
                st.error("ğŸ˜”Â Sorry, something went wrong!")
                st.exception(err)  # shows stack trace only in dev / when expanded
